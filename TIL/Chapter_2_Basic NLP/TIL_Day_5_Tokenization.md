# Tokenization

From Original text into component pieces.

 → process of breaking up.

![image-20210903224517777](C:\Users\count\OneDrive\문서\image-20210903224517777.png)

Figure 1. Tokenization.



Tokens are pieces of the original text.

1) Prefix : at the beginning 
2) Suffix : at the end
3) infix : in between
4) Exception : 
   to split a string into several tokens
   prevent a token from being split when punctuation rules are applied

